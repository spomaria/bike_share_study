---
title: "Untitled"
output: html_document
date: "2023-08-20"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Data Cleaning

The Bike Share data can be downloaded using this (link)[https://divvy-tripdata.s3.amazonaws.com/index.html] To follow this exercise, download the data for August, 2022 to July, 2023.

```{r loading_packages}
library(tidyverse)  #helps wrangle data
library(lubridate)  #helps wrangle date attributes
library(ggplot2)  #helps visualize data
library(skimr)
getwd()
```

```{r reading_data}
#=====================
# STEP 1: COLLECT DATA
#=====================
# Upload Divvy datasets (csv files) here
aug_2022 <- read_csv("202208-divvy-tripdata.csv")
sept_2022 <- read_csv("202209-divvy-publictripdata.csv")
oct_2022 <- read_csv("202210-divvy-tripdata.csv")
nov_2022 <- read_csv("202211-divvy-tripdata.csv")
dec_2022 <- read_csv("202212-divvy-tripdata.csv")
jan_2023 <- read_csv("202301-divvy-tripdata.csv")
feb_2023 <- read_csv("202302-divvy-tripdata.csv")
mar_2023 <- read_csv("202303-divvy-tripdata.csv")
apr_2023 <- read_csv("202304-divvy-tripdata.csv")
may_2023 <- read_csv("202305-divvy-tripdata.csv")
jun_2023 <- read_csv("202306-divvy-tripdata.csv")
jul_2023 <- read_csv("202307-divvy-tripdata.csv")
```

```{r data_wrangling}
#====================================================
# STEP 2: WRANGLE DATA AND COMBINE INTO A SINGLE FILE
#====================================================
# Compare column names each of the files
# While the names don't have to be in the same order, they DO need to match perfectly before we can use a command to join them into one file
colnames(aug_2022)
colnames(sept_2022)
colnames(oct_2022)
colnames(nov_2022)
colnames(dec_2022)
colnames(jan_2023)
colnames(feb_2023)
colnames(mar_2023)
colnames(apr_2023)
colnames(may_2023)
colnames(jun_2023)
colnames(jul_2023)
```

This shows that our column names are the same across the twelve months. We now proceed to inspect the data set for incongruencies.

```{r inspect_data}
# Inspect the data for incongruencies
str(aug_2022)
str(sept_2022)
str(oct_2022)
str(nov_2022)
str(dec_2022)
str(jan_2023)
str(feb_2023)
str(mar_2023)
str(apr_2023)
str(may_2023)
str(jun_2023)
str(jul_2023)
```


```{r combine_data}
# Stack individual month's data frames into one big data frame
all_trips <- bind_rows(aug_2022, sept_2022, oct_2022, nov_2022, dec_2022,
                       jan_2023, feb_2023, mar_2023, apr_2023, may_2023,
                       jun_2023, jul_2023)

# Remove lat and long fields as this data was dropped beginning in 2020
all_trips <- all_trips %>%  
  select(-c(start_lat, start_lng, end_lat, end_lng))

```


```{r data_clean_up}
#======================================================
# STEP 3: CLEAN UP AND ADD DATA TO PREPARE FOR ANALYSIS
#======================================================
# Inspect the new table that has been created
colnames(all_trips)  #List of column names
nrow(all_trips)  #How many rows are in data frame?
dim(all_trips)  #Dimensions of the data frame?
head(all_trips)  #See the first 6 rows of data frame.  Also tail(all_trips)
str(all_trips)  #See list of columns and data types (numeric, character, etc)
summary(all_trips)  #Statistical summary of data. Mainly for numerics
skim_without_charts(all_trips)
```

There are a few problems we will need to fix:
(1) The data can only be aggregated at the ride-level, which is too granular. We will want to add some additional columns of data -- such as day, month, year -- that provide additional opportunities to aggregate the data.

(2) We will want to add a calculated field for length of ride since the data did not have the "tripduration" column. We will add "ride_length" to the entire dataframe for consistency.

N.B.: "Level" is a special property of a column that is retained even if a subset does not contain any values from a specific level
```{r usertype_table}
# Begin by seeing how many observations fall under each usertype
table(all_trips$member_casual)
```

```{r variables_creation}
# Add columns that list the date, month, day, and year of each ride
# This will allow us to aggregate ride data for each month, day, or year ... before completing these operations we could only aggregate at the ride level
# https://www.statmethods.net/input/dates.html more on date formats in R found at that link
all_trips$date <- as.Date(all_trips$started_at) #The default format is yyyy-mm-dd
all_trips$month <- format(as.Date(all_trips$date), "%m")
all_trips$day <- format(as.Date(all_trips$date), "%d")
all_trips$year <- format(as.Date(all_trips$date), "%Y")
all_trips$day_of_week <- format(as.Date(all_trips$date), "%A")

# Add a "ride_length" calculation to all_trips (in seconds)
# https://stat.ethz.ch/R-manual/R-devel/library/base/html/difftime.html
all_trips$ride_length <- difftime(all_trips$ended_at,all_trips$started_at)

# Inspect the structure of the columns
str(all_trips)

#mean(all_trips$ride_length)
```

```{r ride_length_conversion}
# Convert "ride_length" from Factor to numeric so we can run calculations on the data
is.factor(all_trips$ride_length)
all_trips$ride_length <- as.numeric(as.character(all_trips$ride_length))
is.numeric(all_trips$ride_length)
summary(all_trips$ride_length)
```

```{r remove_bad_data}
# Remove "bad" data
# The dataframe includes a few hundred entries when bikes were taken out of docks and checked for quality by Divvy or ride_length was negative
# We will create a new version of the dataframe (v2) since data is being removed
# https://www.datasciencemadesimple.com/delete-or-drop-rows-in-r-with-conditions-2/

# We also drop cells with empty entries
all_trips_v2 <- drop_na(all_trips[!(all_trips$start_station_name == "HQ QR" | 
                              all_trips$ride_length<0),])
```

# STEP 4: CONDUCT DESCRIPTIVE ANALYSIS

```{r}
# Descriptive analysis on ride_length (all figures in seconds)
summary(all_trips_v2$ride_length)
```

```{r member_comparison}
# Compare members and casual users
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = mean)
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = median)
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = max)
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = min)
```

```{r average_per_week_day}
# See the average ride time by each day for members vs casual users
all_trips_v2%>%
  aggregate(ride_length ~ member_casual + day_of_week, FUN = mean)
```

```{r average_per_week_day_ordered}
# Notice that the days of the week are out of order. Let's fix that.
all_trips_v2$day_of_week <- ordered(all_trips_v2$day_of_week, levels=c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))

# Now, let's run the average ride time by each day for members vs casual users
all_trips_v2%>%
  aggregate(ride_length ~ member_casual + day_of_week, FUN = mean)
```

```{r ridership_type_weekday}
# analyze ridership data by type and weekday
all_trips_v2 %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>%  #creates weekday field using wday()
  group_by(member_casual, weekday) %>%  #groups by usertype and weekday
  summarise(number_of_rides = n()							#calculates the number of rides and average duration 
  ,average_duration = mean(ride_length)) %>% 		# calculates the average duration
  arrange(member_casual, weekday)								# sorts
```

```{r rides_per_ridertype}
# Let's visualize the number of rides by rider type
all_trips_v2 %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>% 
  group_by(member_casual, weekday) %>% 
  summarise(number_of_rides = n()
            ,average_duration = mean(ride_length)) %>% 
            arrange(member_casual, weekday)  %>% 
  ggplot(aes(x = weekday, y = number_of_rides, fill = member_casual)) +
  geom_col(position = "dodge")
```
```{r average_duration}
# Let's create a visualization for average duration
all_trips_v2 %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>% 
  group_by(member_casual, weekday) %>% 
  summarise(number_of_rides = n()
            ,average_duration = mean(ride_length)) %>% 
  arrange(member_casual, weekday)  %>% 
  ggplot(aes(x = weekday, y = average_duration, fill = member_casual)) +
  geom_col(position = "dodge")
```

```{r summary_export}
#=================================================
# STEP 5: EXPORT SUMMARY FILE FOR FURTHER ANALYSIS
#=================================================
# Create a csv file that we will visualize in Excel, Tableau, or my presentation software
# N.B.: This file location is for a Mac. If you are working on a PC, change the file location accordingly (most likely "C:\Users\YOUR_USERNAME\Desktop\...") to export the data. You can read more here: https://datatofish.com/export-dataframe-to-csv-in-r/

# We now drop rows with empty cells from our data
counts <- aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual + all_trips_v2$day_of_week, FUN = mean)
write.csv(counts, file = '/home/spomaria/Documents/Spomary-Files/R-Scripts/Bike-Share-Study/avg_ride_length.csv')
write.csv(all_trips_v2, file = '/home/spomaria/Documents/Spomary-Files/R-Scripts/Bike-Share-Study/divvy_tripdata_cleaned.csv')
```
